{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from GetAprilTrainTestData import GetAprilTrainTestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13413 13413\n"
     ]
    }
   ],
   "source": [
    "X, y = GetAprilTrainTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (13413, 3947)\n"
     ]
    }
   ],
   "source": [
    "# Now need to one hot encode all the stuff in X that is categorical. \n",
    "X = pd.get_dummies(X)\n",
    "print(\"Shape\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10059 10059 3354 3354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=20)\n",
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data. This may not be necessary for linear regressions, but will be if I go to some other scheme\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "# Tranform all of the data based on the scaler fit calculated above\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10059 10059 3354 3354\n",
      "Number of features =  3947\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_scaled), len(y_train_scaled), len(X_test_scaled), len(y_test_scaled))\n",
    "print(\"Number of features = \", len(X_train_scaled[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_keras_regressor():\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    model = Sequential()\n",
    "    # Create keras input layer and first hidden layer\n",
    "    number_inputs = len(X_train_scaled[0])\n",
    "    number_hidden_nodes = 100\n",
    "    activation_fn=\"softplus\"\n",
    "    model.add(Dense(units=number_hidden_nodes, activation=activation_fn, input_dim=number_inputs))\n",
    "    model.add(Dense(units=number_hidden_nodes, activation=activation_fn))\n",
    "    model.add(Dense(units=number_hidden_nodes, activation=activation_fn))\n",
    "    model.add(Dense(units=number_hidden_nodes, activation=activation_fn))\n",
    "    model.add(Dense(units=number_hidden_nodes, activation=activation_fn))\n",
    "    # Create keras output layer. There is no activation function since we want values directly\n",
    "    model.add(Dense(units=1))\n",
    "    # Compile the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics = [\"mae\", \"accuracy\"])\n",
    "    print(model.summary(), activation=\"relu\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "regressor = KerasRegressor(build_fn=build_keras_regressor, batch_size=20,  epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 100)               274400    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 314,901\n",
      "Trainable params: 314,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5967/5967 [==============================] - 3s 499us/step - loss: 0.0227 - mean_absolute_error: 0.0777 - acc: 0.0587\n",
      "Epoch 2/100\n",
      "5967/5967 [==============================] - 3s 450us/step - loss: 0.0048 - mean_absolute_error: 0.0399 - acc: 0.0600\n",
      "Epoch 3/100\n",
      "5967/5967 [==============================] - 3s 434us/step - loss: 0.0042 - mean_absolute_error: 0.0394 - acc: 0.0597 2s - loss: 0.0\n",
      "Epoch 4/100\n",
      "5967/5967 [==============================] - 3s 447us/step - loss: 0.0038 - mean_absolute_error: 0.0396 - acc: 0.0600\n",
      "Epoch 5/100\n",
      "5967/5967 [==============================] - 2s 414us/step - loss: 0.0032 - mean_absolute_error: 0.0344 - acc: 0.0602\n",
      "Epoch 6/100\n",
      "5967/5967 [==============================] - 3s 427us/step - loss: 0.0038 - mean_absolute_error: 0.0360 - acc: 0.0598\n",
      "Epoch 7/100\n",
      "5967/5967 [==============================] - 3s 434us/step - loss: 0.0027 - mean_absolute_error: 0.0320 - acc: 0.0600\n",
      "Epoch 8/100\n",
      "5967/5967 [==============================] - 3s 423us/step - loss: 0.0042 - mean_absolute_error: 0.0356 - acc: 0.0600\n",
      "Epoch 9/100\n",
      "5967/5967 [==============================] - 3s 475us/step - loss: 0.0023 - mean_absolute_error: 0.0292 - acc: 0.0602\n",
      "Epoch 10/100\n",
      "5967/5967 [==============================] - 2s 406us/step - loss: 0.0022 - mean_absolute_error: 0.0284 - acc: 0.0602\n",
      "Epoch 11/100\n",
      "5967/5967 [==============================] - 3s 463us/step - loss: 0.0021 - mean_absolute_error: 0.0282 - acc: 0.0602\n",
      "Epoch 12/100\n",
      "5967/5967 [==============================] - 3s 469us/step - loss: 0.0018 - mean_absolute_error: 0.0256 - acc: 0.0603\n",
      "Epoch 13/100\n",
      "5967/5967 [==============================] - 3s 541us/step - loss: 0.0017 - mean_absolute_error: 0.0244 - acc: 0.0602\n",
      "Epoch 14/100\n",
      "5967/5967 [==============================] - 3s 508us/step - loss: 0.0017 - mean_absolute_error: 0.0231 - acc: 0.0602\n",
      "Epoch 15/100\n",
      "5967/5967 [==============================] - 3s 561us/step - loss: 0.0018 - mean_absolute_error: 0.0265 - acc: 0.0602\n",
      "Epoch 16/100\n",
      "5967/5967 [==============================] - 3s 498us/step - loss: 0.0016 - mean_absolute_error: 0.0250 - acc: 0.0602\n",
      "Epoch 17/100\n",
      "5967/5967 [==============================] - 4s 602us/step - loss: 0.0015 - mean_absolute_error: 0.0222 - acc: 0.0602\n",
      "Epoch 18/100\n",
      "5967/5967 [==============================] - 4s 638us/step - loss: 0.0016 - mean_absolute_error: 0.0235 - acc: 0.0602\n",
      "Epoch 19/100\n",
      "5967/5967 [==============================] - 4s 641us/step - loss: 0.0015 - mean_absolute_error: 0.0233 - acc: 0.0602\n",
      "Epoch 20/100\n",
      "5967/5967 [==============================] - 3s 535us/step - loss: 0.0016 - mean_absolute_error: 0.0243 - acc: 0.0602\n",
      "Epoch 21/100\n",
      "5967/5967 [==============================] - 4s 620us/step - loss: 0.0016 - mean_absolute_error: 0.0239 - acc: 0.0602\n",
      "Epoch 22/100\n",
      "5967/5967 [==============================] - 3s 454us/step - loss: 0.0013 - mean_absolute_error: 0.0210 - acc: 0.0602\n",
      "Epoch 23/100\n",
      "5967/5967 [==============================] - 3s 520us/step - loss: 0.0014 - mean_absolute_error: 0.0222 - acc: 0.0602\n",
      "Epoch 24/100\n",
      "5967/5967 [==============================] - 3s 435us/step - loss: 0.0013 - mean_absolute_error: 0.0215 - acc: 0.0602\n",
      "Epoch 25/100\n",
      "5967/5967 [==============================] - 3s 498us/step - loss: 0.0015 - mean_absolute_error: 0.0231 - acc: 0.0602\n",
      "Epoch 26/100\n",
      "5967/5967 [==============================] - 3s 422us/step - loss: 0.0014 - mean_absolute_error: 0.0230 - acc: 0.0602\n",
      "Epoch 27/100\n",
      "5967/5967 [==============================] - 3s 458us/step - loss: 0.0012 - mean_absolute_error: 0.0199 - acc: 0.0602\n",
      "Epoch 28/100\n",
      "5967/5967 [==============================] - 3s 421us/step - loss: 0.0013 - mean_absolute_error: 0.0216 - acc: 0.0602\n",
      "Epoch 29/100\n",
      "5967/5967 [==============================] - 3s 543us/step - loss: 0.0011 - mean_absolute_error: 0.0195 - acc: 0.0602\n",
      "Epoch 30/100\n",
      "5967/5967 [==============================] - 3s 451us/step - loss: 0.0010 - mean_absolute_error: 0.0190 - acc: 0.0602\n",
      "Epoch 31/100\n",
      "5967/5967 [==============================] - 3s 472us/step - loss: 0.0012 - mean_absolute_error: 0.0204 - acc: 0.0602\n",
      "Epoch 32/100\n",
      "5967/5967 [==============================] - 3s 517us/step - loss: 0.0011 - mean_absolute_error: 0.0198 - acc: 0.0602\n",
      "Epoch 33/100\n",
      "5967/5967 [==============================] - 3s 522us/step - loss: 0.0012 - mean_absolute_error: 0.0207 - acc: 0.0602\n",
      "Epoch 34/100\n",
      "5967/5967 [==============================] - 3s 459us/step - loss: 0.0012 - mean_absolute_error: 0.0201 - acc: 0.0602\n",
      "Epoch 35/100\n",
      "5967/5967 [==============================] - 3s 534us/step - loss: 0.0011 - mean_absolute_error: 0.0196 - acc: 0.0602\n",
      "Epoch 36/100\n",
      "5967/5967 [==============================] - 3s 474us/step - loss: 0.0010 - mean_absolute_error: 0.0192 - acc: 0.0602\n",
      "Epoch 37/100\n",
      "5967/5967 [==============================] - 3s 475us/step - loss: 9.5213e-04 - mean_absolute_error: 0.0187 - acc: 0.0602\n",
      "Epoch 38/100\n",
      "5967/5967 [==============================] - 3s 483us/step - loss: 9.3218e-04 - mean_absolute_error: 0.0185 - acc: 0.0602\n",
      "Epoch 39/100\n",
      "5967/5967 [==============================] - 3s 539us/step - loss: 8.6039e-04 - mean_absolute_error: 0.0167 - acc: 0.0603\n",
      "Epoch 40/100\n",
      "5967/5967 [==============================] - 3s 532us/step - loss: 9.5670e-04 - mean_absolute_error: 0.0194 - acc: 0.0602\n",
      "Epoch 41/100\n",
      "5967/5967 [==============================] - 3s 548us/step - loss: 9.0125e-04 - mean_absolute_error: 0.0179 - acc: 0.0603\n",
      "Epoch 42/100\n",
      "5967/5967 [==============================] - 4s 662us/step - loss: 9.3872e-04 - mean_absolute_error: 0.0192 - acc: 0.0603\n",
      "Epoch 43/100\n",
      "5967/5967 [==============================] - 4s 665us/step - loss: 9.9608e-04 - mean_absolute_error: 0.0193 - acc: 0.0603\n",
      "Epoch 44/100\n",
      "5967/5967 [==============================] - 4s 615us/step - loss: 7.8245e-04 - mean_absolute_error: 0.0160 - acc: 0.0603\n",
      "Epoch 45/100\n",
      "5967/5967 [==============================] - 4s 613us/step - loss: 7.6762e-04 - mean_absolute_error: 0.0168 - acc: 0.0603\n",
      "Epoch 46/100\n",
      "5967/5967 [==============================] - 3s 439us/step - loss: 8.1740e-04 - mean_absolute_error: 0.0178 - acc: 0.0603\n",
      "Epoch 47/100\n",
      "5967/5967 [==============================] - 3s 498us/step - loss: 7.6722e-04 - mean_absolute_error: 0.0164 - acc: 0.0603\n",
      "Epoch 48/100\n",
      "5967/5967 [==============================] - 3s 453us/step - loss: 8.1250e-04 - mean_absolute_error: 0.0171 - acc: 0.0603\n",
      "Epoch 49/100\n",
      "5967/5967 [==============================] - 3s 507us/step - loss: 7.6983e-04 - mean_absolute_error: 0.0167 - acc: 0.0603\n",
      "Epoch 50/100\n",
      "5967/5967 [==============================] - 3s 447us/step - loss: 6.8254e-04 - mean_absolute_error: 0.0161 - acc: 0.0603\n",
      "Epoch 51/100\n",
      "5967/5967 [==============================] - 3s 459us/step - loss: 8.8041e-04 - mean_absolute_error: 0.0177 - acc: 0.0603\n",
      "Epoch 52/100\n",
      "5967/5967 [==============================] - 3s 468us/step - loss: 8.4926e-04 - mean_absolute_error: 0.0173 - acc: 0.0602\n",
      "Epoch 53/100\n",
      "5967/5967 [==============================] - 3s 526us/step - loss: 6.7019e-04 - mean_absolute_error: 0.0152 - acc: 0.0603\n",
      "Epoch 54/100\n",
      "5967/5967 [==============================] - 3s 479us/step - loss: 6.4678e-04 - mean_absolute_error: 0.0152 - acc: 0.0603\n",
      "Epoch 55/100\n",
      "5967/5967 [==============================] - 3s 536us/step - loss: 6.7163e-04 - mean_absolute_error: 0.0158 - acc: 0.0603\n",
      "Epoch 56/100\n",
      "5967/5967 [==============================] - 3s 500us/step - loss: 6.8864e-04 - mean_absolute_error: 0.0160 - acc: 0.0603\n",
      "Epoch 57/100\n",
      "5967/5967 [==============================] - 3s 573us/step - loss: 7.1116e-04 - mean_absolute_error: 0.0163 - acc: 0.0603\n",
      "Epoch 58/100\n",
      "5967/5967 [==============================] - 4s 658us/step - loss: 7.4920e-04 - mean_absolute_error: 0.0158 - acc: 0.0603\n",
      "Epoch 59/100\n",
      "5967/5967 [==============================] - 5s 798us/step - loss: 6.9849e-04 - mean_absolute_error: 0.0170 - acc: 0.0603\n",
      "Epoch 60/100\n",
      "5967/5967 [==============================] - 6s 932us/step - loss: 6.3128e-04 - mean_absolute_error: 0.0148 - acc: 0.0603\n",
      "Epoch 61/100\n",
      "5967/5967 [==============================] - 4s 642us/step - loss: 7.4465e-04 - mean_absolute_error: 0.0163 - acc: 0.0603\n",
      "Epoch 62/100\n",
      "5967/5967 [==============================] - 5s 781us/step - loss: 8.6357e-04 - mean_absolute_error: 0.0176 - acc: 0.0602\n",
      "Epoch 63/100\n",
      "5967/5967 [==============================] - 5s 787us/step - loss: 7.0501e-04 - mean_absolute_error: 0.0156 - acc: 0.0603\n",
      "Epoch 64/100\n",
      "5967/5967 [==============================] - 3s 578us/step - loss: 5.4266e-04 - mean_absolute_error: 0.0138 - acc: 0.0603\n",
      "Epoch 65/100\n",
      "5967/5967 [==============================] - 4s 621us/step - loss: 6.3315e-04 - mean_absolute_error: 0.0154 - acc: 0.0603\n",
      "Epoch 66/100\n",
      "5967/5967 [==============================] - 4s 683us/step - loss: 6.8252e-04 - mean_absolute_error: 0.0163 - acc: 0.0603\n",
      "Epoch 67/100\n",
      "5967/5967 [==============================] - 4s 621us/step - loss: 6.0965e-04 - mean_absolute_error: 0.0150 - acc: 0.0603\n",
      "Epoch 68/100\n",
      "5967/5967 [==============================] - 5s 810us/step - loss: 6.2669e-04 - mean_absolute_error: 0.0146 - acc: 0.0603\n",
      "Epoch 69/100\n",
      "5967/5967 [==============================] - 4s 590us/step - loss: 6.7429e-04 - mean_absolute_error: 0.0158 - acc: 0.0603\n",
      "Epoch 70/100\n",
      "5967/5967 [==============================] - 3s 571us/step - loss: 5.5410e-04 - mean_absolute_error: 0.0141 - acc: 0.0603\n",
      "Epoch 71/100\n",
      "5967/5967 [==============================] - 4s 634us/step - loss: 5.5096e-04 - mean_absolute_error: 0.0141 - acc: 0.0603\n",
      "Epoch 72/100\n",
      "5967/5967 [==============================] - 3s 561us/step - loss: 5.6360e-04 - mean_absolute_error: 0.0148 - acc: 0.0603\n",
      "Epoch 73/100\n",
      "5967/5967 [==============================] - 3s 586us/step - loss: 5.3432e-04 - mean_absolute_error: 0.0139 - acc: 0.0603\n",
      "Epoch 74/100\n",
      "5967/5967 [==============================] - 3s 494us/step - loss: 6.8137e-04 - mean_absolute_error: 0.0147 - acc: 0.0603\n",
      "Epoch 75/100\n",
      "5967/5967 [==============================] - 3s 580us/step - loss: 5.4861e-04 - mean_absolute_error: 0.0142 - acc: 0.0603\n",
      "Epoch 76/100\n",
      "5967/5967 [==============================] - 3s 561us/step - loss: 5.3345e-04 - mean_absolute_error: 0.0142 - acc: 0.0603\n",
      "Epoch 77/100\n",
      "5967/5967 [==============================] - 3s 586us/step - loss: 6.1207e-04 - mean_absolute_error: 0.0161 - acc: 0.0603\n",
      "Epoch 78/100\n",
      "5967/5967 [==============================] - 3s 578us/step - loss: 5.0926e-04 - mean_absolute_error: 0.0132 - acc: 0.0603\n",
      "Epoch 79/100\n",
      "5967/5967 [==============================] - 3s 533us/step - loss: 6.0942e-04 - mean_absolute_error: 0.0137 - acc: 0.0603\n",
      "Epoch 80/100\n",
      "5967/5967 [==============================] - 4s 590us/step - loss: 4.8131e-04 - mean_absolute_error: 0.0126 - acc: 0.0603\n",
      "Epoch 81/100\n",
      "5967/5967 [==============================] - 4s 696us/step - loss: 5.0123e-04 - mean_absolute_error: 0.0136 - acc: 0.0603\n",
      "Epoch 82/100\n",
      "5967/5967 [==============================] - 5s 760us/step - loss: 5.9880e-04 - mean_absolute_error: 0.0152 - acc: 0.0603\n",
      "Epoch 83/100\n",
      "5967/5967 [==============================] - 5s 803us/step - loss: 4.8658e-04 - mean_absolute_error: 0.0133 - acc: 0.0603\n",
      "Epoch 84/100\n",
      "5967/5967 [==============================] - 4s 684us/step - loss: 4.6880e-04 - mean_absolute_error: 0.0128 - acc: 0.0603\n",
      "Epoch 85/100\n",
      "5967/5967 [==============================] - 4s 696us/step - loss: 4.8237e-04 - mean_absolute_error: 0.0133 - acc: 0.0603\n",
      "Epoch 86/100\n",
      "5967/5967 [==============================] - 5s 804us/step - loss: 4.4596e-04 - mean_absolute_error: 0.0125 - acc: 0.0603\n",
      "Epoch 87/100\n",
      "5967/5967 [==============================] - 4s 731us/step - loss: 5.2910e-04 - mean_absolute_error: 0.0136 - acc: 0.0603\n",
      "Epoch 88/100\n",
      "5967/5967 [==============================] - 4s 710us/step - loss: 5.4418e-04 - mean_absolute_error: 0.0142 - acc: 0.0603\n",
      "Epoch 89/100\n",
      "5967/5967 [==============================] - 4s 671us/step - loss: 4.1553e-04 - mean_absolute_error: 0.0121 - acc: 0.0603\n",
      "Epoch 90/100\n",
      "5967/5967 [==============================] - 4s 698us/step - loss: 4.3164e-04 - mean_absolute_error: 0.0125 - acc: 0.0603\n",
      "Epoch 91/100\n",
      "5967/5967 [==============================] - 5s 777us/step - loss: 4.4701e-04 - mean_absolute_error: 0.0126 - acc: 0.0603\n",
      "Epoch 92/100\n",
      "5967/5967 [==============================] - 5s 781us/step - loss: 4.5586e-04 - mean_absolute_error: 0.0129 - acc: 0.0603\n",
      "Epoch 93/100\n",
      "5967/5967 [==============================] - 4s 735us/step - loss: 5.2748e-04 - mean_absolute_error: 0.0145 - acc: 0.0603\n",
      "Epoch 94/100\n",
      "5967/5967 [==============================] - 5s 780us/step - loss: 5.5142e-04 - mean_absolute_error: 0.0139 - acc: 0.0603\n",
      "Epoch 95/100\n",
      "5967/5967 [==============================] - 4s 688us/step - loss: 5.0916e-04 - mean_absolute_error: 0.0143 - acc: 0.0603\n",
      "Epoch 96/100\n",
      "5967/5967 [==============================] - 5s 774us/step - loss: 4.3267e-04 - mean_absolute_error: 0.0117 - acc: 0.0603\n",
      "Epoch 97/100\n",
      "5967/5967 [==============================] - 5s 839us/step - loss: 4.4943e-04 - mean_absolute_error: 0.0123 - acc: 0.0603\n",
      "Epoch 98/100\n",
      "5967/5967 [==============================] - 5s 779us/step - loss: 4.5003e-04 - mean_absolute_error: 0.0126 - acc: 0.0603\n",
      "Epoch 99/100\n",
      "5967/5967 [==============================] - 4s 646us/step - loss: 4.3233e-04 - mean_absolute_error: 0.0123 - acc: 0.0603\n",
      "Epoch 100/100\n",
      "5967/5967 [==============================] - 4s 680us/step - loss: 4.9151e-04 - mean_absolute_error: 0.0131 - acc: 0.0603\n"
     ]
    }
   ],
   "source": [
    "results = regressor.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasRegressor' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-dd5314cee864>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m         \"\"\"\n\u001b[0;32m    341\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasRegressor' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "regressor.score(X_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasRegressor' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b4d7319a6040>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \"\"\"\n\u001b[0;32m    322\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasRegressor' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "predictions= regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_recovered = X_scaler.inverse_transform(X_train_scaled)\n",
    "X_test_recovered = X_scaler.inverse_transform(X_test_scaled)\n",
    "y_train_recovered = y_scaler.inverse_transform(y_train_scaled)\n",
    "y_test_recovered = y_scaler.inverse_transform(y_test_scaled)\n",
    "predictions_recovered = y_scaler.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x35ee3828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(predictions_recovered, np.concatenate(y_test_recovered, axis=0))\n",
    "plt.hlines(y=1, xmin=predictions.min(), xmax=predictions.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.00000000e+00, 3.20000000e+01, 3.92000000e+02, ...,\n",
       "       0.00000000e+00, 2.16840434e-19, 1.00000000e+00])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_recovered[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.844],\n",
       "       [0.817],\n",
       "       [0.996],\n",
       "       ...,\n",
       "       [0.905],\n",
       "       [0.993],\n",
       "       [0.95 ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0277036, 1.0231518, 1.033953 , ..., 1.0270336, 1.0334805,\n",
       "       1.0272079], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SETUP_TIME</th>\n",
       "      <th>CYCLES</th>\n",
       "      <th>TESTED_UNITS</th>\n",
       "      <th>RESCREEN_RULE</th>\n",
       "      <th>MSE_RULE</th>\n",
       "      <th>SPC_RULE</th>\n",
       "      <th>INDEX_RULE</th>\n",
       "      <th>MCBJ_RULE</th>\n",
       "      <th>SETUPTIME_RULE</th>\n",
       "      <th>MSE_UNIT</th>\n",
       "      <th>...</th>\n",
       "      <th>TESTERHEAD_vl76_2</th>\n",
       "      <th>TESTERHEAD_vl91_1</th>\n",
       "      <th>TESTERHEAD_vl93_1</th>\n",
       "      <th>TESTERHEAD_vl95_1</th>\n",
       "      <th>TESTERHEAD_vl98_1</th>\n",
       "      <th>TESTERHEAD_vl99_1</th>\n",
       "      <th>TESTERHEAD_vl9_1</th>\n",
       "      <th>LOTSCREENTYPE_FIRST_PASS</th>\n",
       "      <th>MSYE</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.168404e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.168404e-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844</td>\n",
       "      <td>1.027704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2985.4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.168404e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.168404e-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.817</td>\n",
       "      <td>1.023152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.9</td>\n",
       "      <td>420.0</td>\n",
       "      <td>959.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.168404e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.168404e-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.033953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.3</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>14103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.168404e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.168404e-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.033793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.168404e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.168404e-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.031703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2745 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SETUP_TIME  CYCLES  TESTED_UNITS  RESCREEN_RULE  MSE_RULE  SPC_RULE  \\\n",
       "0         8.0    32.0         392.0            1.0       1.0       1.0   \n",
       "1      2985.4    35.0         164.0            1.0       1.0       1.0   \n",
       "2        18.9   420.0         959.0            1.0       1.0       1.0   \n",
       "3        26.3  1157.0       14103.0            1.0       1.0       1.0   \n",
       "4         2.0   159.0        1439.0            1.0       1.0       1.0   \n",
       "\n",
       "   INDEX_RULE  MCBJ_RULE  SETUPTIME_RULE  MSE_UNIT     ...       \\\n",
       "0         1.0        1.0    1.000000e+00     1.000     ...        \n",
       "1         1.0        1.0    1.110223e-16     1.000     ...        \n",
       "2         1.0        1.0    1.000000e+00     0.998     ...        \n",
       "3         1.0        1.0    1.000000e+00     0.949     ...        \n",
       "4         1.0        1.0    1.000000e+00     0.999     ...        \n",
       "\n",
       "   TESTERHEAD_vl76_2  TESTERHEAD_vl91_1  TESTERHEAD_vl93_1  TESTERHEAD_vl95_1  \\\n",
       "0                0.0                0.0                0.0       2.168404e-19   \n",
       "1                0.0                0.0                0.0       2.168404e-19   \n",
       "2                0.0                0.0                0.0       2.168404e-19   \n",
       "3                0.0                0.0                0.0       2.168404e-19   \n",
       "4                0.0                0.0                0.0       2.168404e-19   \n",
       "\n",
       "   TESTERHEAD_vl98_1  TESTERHEAD_vl99_1  TESTERHEAD_vl9_1  \\\n",
       "0                0.0                0.0      2.168404e-19   \n",
       "1                0.0                0.0      2.168404e-19   \n",
       "2                0.0                0.0      2.168404e-19   \n",
       "3                0.0                0.0      2.168404e-19   \n",
       "4                0.0                0.0      2.168404e-19   \n",
       "\n",
       "   LOTSCREENTYPE_FIRST_PASS   MSYE  Predictions  \n",
       "0                       1.0  0.844     1.027704  \n",
       "1                       1.0  0.817     1.023152  \n",
       "2                       1.0  0.996     1.033953  \n",
       "3                       1.0  0.995     1.033793  \n",
       "4                       1.0  0.999     1.031703  \n",
       "\n",
       "[5 rows x 2745 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df=pd.DataFrame(X_test_recovered)\n",
    "out_df.columns=X.columns\n",
    "out_df[\"MSYE\"] = list(np.concatenate(y_test_recovered, axis=0))\n",
    "out_df[\"Predictions\"] = predictions_recovered\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv(\"data/product_test_data_KerasNeuralNet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
